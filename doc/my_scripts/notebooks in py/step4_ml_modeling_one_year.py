# -*- coding: utf-8 -*-
"""step4_ml_modeling_one_year.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iomm5Li32ZVo12tVYWa1KP02K6JGMb0K

# Build ML models to predict whether a pixel is ignited
"""

import os
import pandas as pd
import geopandas as gpd
import xarray as xr
import math
import rasterio
from rasterio.merge import merge
from rasterio.io import MemoryFile
import numpy as np
from rasterio.io import MemoryFile
from rasterio.windows import Window

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

folder = '../../climada_petals/data/wildfire/output/2013/'
df = gpd.read_file(os.path.join(folder, 'ignited_eu_2013_gdf'))
df

df['ignited'].value_counts()

"""## 1. Preprocessing Data

### Check whether longitude is in the correct range
"""

df_false = df[df['ignited'] == False].sample(n=10000, replace=False, random_state=42)
df_false['longitude'].describe()

import contextily as ctx
import matplotlib.pyplot as plt

geo_bound_eu = (-31, 34, 40 ,72)
fig, ax = plt.subplots(figsize=(10, 10))
df_false.plot(ax=ax, column='fwi', legend=True, cmap='hot', markersize=5)
ax.set_xlim(geo_bound_eu[0], geo_bound_eu[2])
ax.set_ylim(geo_bound_eu[1], geo_bound_eu[3])
ctx.add_basemap(ax, crs='EPSG:4326', source=ctx.providers.OpenStreetMap.Mapnik)

"""### Map land cover to fire ignition probability"""

# Map land cover type to ignition probability according to Climada Master thesis Table 2.1
# and Land Cover User Manual Table 4 Discrete classification coding
# land_cover_map_dict = {
#     0: 0, # no input data
#     111: 1, 113: 1, 112: 1, 114: 1, 115: 1, 116: 1, 121: 1, 123: 1, 122: 1, 124: 1, 125: 1, 126: 1, # forest
#     20: 1, # shrubs
#     30: 1, # Herbaceous vegetation
#     90: 0.85, # Herbaceous wetland
#     100: 1, # Moss and lichen
#     60: 0, # Bare / sparse vegetation
#     40: 0, # cropland
#     50: 0, # Urban / built up
#     70: 0, # Snow and ice
#     80: 0, # permanent water bodies
#     200: 0, # open sea
# }
#
# df['land_cover'] = df['land_cover'].map(land_cover_map_dict)
# df['land_cover'].value_counts()
# df.rename(columns={'land_cover': 'ignition_probability'}, inplace=True)

# Run this code instead if you don't want to map land cover to ignition probability
# one hot encode land cover
df = pd.get_dummies(df, columns=['land_cover'], prefix='land_cover')

"""### Only retain month for date column then take sin and cos"""

# Convert the 'date' column to datetime format
df['date'] = pd.to_datetime(df['date'])

# Extract the month from the 'date' column
df['month'] = df['date'].dt.month

print(df['month'].unique())

# Create 'month_sin' and 'month_cos' columns
df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
df = df.drop(columns=['month', 'date', 'distance_km', 'confidence', 'geometry'])

"""### Make sure there is no NA values"""

df.isna().sum()

df['fwi'].fillna(0, inplace=True)

"""## 2. Training ML models with Optuna optimization and Cross Validation"""

import optuna
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier

"""### Train test split"""

# # Random split
# X_train_val, X_test, y_train_val, y_test = train_test_split(df.drop(columns=['ignited']), df['ignited'], test_size=0.1, random_state=42, shuffle=True)
# print(X_train_val.shape, X_test.shape)

# Use France as test set and rest of EU as training set
GEO_BOUND_FRANCE = (-5, 41, 10, 51)
france_mask = (df['longitude'] >= GEO_BOUND_FRANCE[0]) & (df['longitude'] <= GEO_BOUND_FRANCE[2]) & (df['latitude'] >= GEO_BOUND_FRANCE[1]) & (df['latitude'] <= GEO_BOUND_FRANCE[3])

X = df.drop(columns=['ignited'])
y = df['ignited']
X_train_val, X_test = X[~france_mask], X[france_mask]
y_train_val, y_test = y[~france_mask], y[france_mask]
print(X_train_val.shape, X_test.shape)

X.columns

# Run this code if you need to exclude latitude, longitude, brightness, bright_t31
X_train_val = X_train_val.drop(columns=['latitude', 'longitude', 'brightness', 'bright_t31'])
X_test = X_test.drop(columns=['latitude', 'longitude', 'brightness', 'bright_t31'])

"""### Hyperparameter tuning with Optuna and cross validation"""

classifier_names = ["LogisticRegression", "XGBClassifier"]

# Create dictionaries to store the best models, hyperparameters, and scores for each ML model
best_models = {}
best_params = {}
best_scores = {}

for name in classifier_names:
    best_scores[name] = 0
    best_params[name] = None
    best_models[name] = None

# function for both Logistic Regression and XGBoost
def logisticregression_objective(trial):
    classifier_name = "LogisticRegression"
    logistic_c = trial.suggest_float('logistic_c', 1e-5, 1e5, log=True)

    classifier_obj = LogisticRegression(C=logistic_c, random_state=42)
    # Create a pipeline with a scaler and the updated model
    model_pipeline = make_pipeline(StandardScaler(), classifier_obj)

    # Perform cross-validation
    score = cross_val_score(model_pipeline, X_train_val, y_train_val, cv=5, n_jobs=-1, scoring='roc_auc').mean() # may also use: scoring='accuracy'

    if score > best_scores[classifier_name]:
        best_scores[classifier_name] = score
        best_params[classifier_name] = trial.params
        best_models[classifier_name] = classifier_obj # classifier_obj remain untrained

    return score

def xgboost_objective(trial):
    classifier_name = "XGBClassifier"
    xgb_params = {
        'n_estimators': trial.suggest_int('n_estimators', 200, 2000),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),
        'subsample': trial.suggest_float('subsample', 0.2, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
        'gamma': trial.suggest_float('gamma', 0, 5),
        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),
        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),
        'random_state': 42
    }
    classifier_obj = XGBClassifier(**xgb_params)
    model_pipeline = classifier_obj


    # Perform cross-validation
    score = cross_val_score(model_pipeline, X_train_val, y_train_val, cv=5, n_jobs=-1, scoring='roc_auc').mean() # scoring='accuracy'

    if score > best_scores[classifier_name]:
        best_scores[classifier_name] = score
        best_params[classifier_name] = trial.params
        best_models[classifier_name] = classifier_obj # classifier_obj remain untrained

    return score

study = optuna.create_study(sampler=optuna.samplers.GPSampler(), storage='sqlite:///db.sqlite3', direction='maximize')
study.optimize(logisticregression_objective, n_trials=20)

study = optuna.create_study(sampler=optuna.samplers.GPSampler(), storage='sqlite:///db.sqlite3', direction='maximize')
study.optimize(xgboost_objective, n_trials=100)

"""### Training accuracy, Test accuracy and F-1 score"""

# Run this code if you need to rerun training and test accuracy
# for name in classifier_names:
#     if name == 'XGBClassifier':
#         model = XGBClassifier(**best_params[name], random_state=42)
#     elif name == 'LogisticRegression':
#         model = LogisticRegression(C=best_params[name]['logistic_c'], random_state=42)
#     else:
#         raise ValueError("Invalid classifier name")

for name in classifier_names:
    print("Model:", name)
    print("Best hyperparameters:", best_params[name])

    if name == "LogisticRegression":
        # Increase max_iter in the LogisticRegression model
        best_models[name].set_params(max_iter=200)

        # Create a pipeline with a scaler and the updated model
        model_pipeline = make_pipeline(StandardScaler(), best_models[name])
    else:
        model_pipeline = best_models[name]

    # Fit the best model on the training data
    model_pipeline.fit(X_train_val, y_train_val)

    # Calculate the training accuracy
    train_accuracy = model_pipeline.score(X_train_val, y_train_val)
    print("Training accuracy:", train_accuracy)
    test_accuracy = model_pipeline.score(X_test, y_test)
    print("Test accuracy:", test_accuracy)
    y_pred = model_pipeline.predict(X_test)
    # Print the classification report
    print(classification_report(y_test, y_pred))
    # Print the confusion matrix
    print(confusion_matrix(y_test, y_pred))

"""### Feature importance"""

classifier_names

for name in classifier_names:
    if name == "LogisticRegression":
        reg_coff = best_models[name].coef_[0]
        feature_importance_df = pd.DataFrame({'feature': X_train_val.columns, 'coefficient': reg_coff})
        feature_importance_df = feature_importance_df.sort_values(by='coefficient', ascending=False)
        print(name)
        print(feature_importance_df)
        print('------------------------------------')
    elif name == "XGBClassifier":
        feature_importance = best_models[name].feature_importances_
        feature_importance_df = pd.DataFrame({'feature': X_train_val.columns, 'importance': feature_importance})
        feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)
        print(name)
        print(feature_importance_df)
        print('------------------------------------')

"""Logistic Regression calculates feature importance based on the coefficients assigned to each feature. These coefficients represent the change in the log odds of the outcome for a one-unit change in the feature. Features with larger absolute coefficients are considered more important. This method is linear and assumes a direct relationship between the feature and the outcome.  

XGBoost, on the other hand, uses an ensemble of decision trees. It calculates feature importance as the gain, which measures the contribution of each feature to the model's performance. The importance can be based on how often a feature is used to split the data across all trees (frequency), the total gain of splits which use the feature (gain), or the average gain of splits which use the feature (average gain). This method captures non-linear relationships and interactions between features.  

Given these differences, Logistic Regression might prioritize features that have a strong linear relationship with the outcome, while XGBoost might highlight features that are more critical in terms of interaction with other features or in splitting the data in complex, non-linear ways. This discrepancy is especially common in datasets where relationships between features and the target variable are not strictly linear or when features interact with each other in complex ways.
"""

# permutation feature importance
# Run this code if you need to rerun training and test accuracy
for name in classifier_names:
    if name == 'XGBClassifier':
        model = XGBClassifier(**best_params[name], random_state=42)
    elif name == 'LogisticRegression':
        model = LogisticRegression(C=best_params[name]['logistic_c'], random_state=42)
    else:
        raise ValueError("Invalid classifier name")


from sklearn.inspection import permutation_importance

for name in classifier_names:
    if name == "LogisticRegression":
        # Increase max_iter in the LogisticRegression model
        best_models[name].set_params(max_iter=200)

        # Create a pipeline with a scaler and the updated model
        model_pipeline = make_pipeline(StandardScaler(), best_models[name])
    else:
        model_pipeline = best_models[name]

    # Fit the best model on the training data
    model_pipeline.fit(X, y)
    # Calculate permutation feature importance
    perm_importance = permutation_importance(model_pipeline, X, y, n_repeats=10, random_state=42)
    feature_importance_df = pd.DataFrame({'feature': X.columns, 'importance': perm_importance.importances_mean})
    print(name)
    print(feature_importance_df)
    print('------------------------------------')



"""# 3. Visualization"""

df_sub = df.sample(n=10000, replace=False)

df_sub.isna().sum()

import seaborn as sns
import matplotlib.pyplot as plt
for col in df_sub.columns:
    if col != 'ignited':
        sns.lmplot(x=col, y='ignited', data=df_sub, logistic=True, y_jitter=0.03, scatter_kws={'alpha': 0.3, 's': 3})
        plt.show()

correlation_matrix = df.corr()
correlation_matrix

sns.heatmap(df.corr(), annot=True, fmt=".2f")


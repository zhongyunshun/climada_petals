{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-23T00:23:54.200467Z",
     "start_time": "2024-07-23T00:23:54.010464Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Load relevant functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9012436159c5902f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.1 Load the function to group the DataFrame into fire events"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29b3b14f360028ce"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def group_into_fire_events(df):\n",
    "    \"\"\"\n",
    "    This function takes in a DataFrame and returns a copy of the DataFrame with three additional columns:\n",
    "    'date_cluster', 'regional_cluster', and 'event_id'.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        df (pd.DataFrame): The output DataFrame with three additional columns: 'date_cluster', 'regional_cluster', and 'event_id'.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    df.rename(columns={'date':'acq_date', 'latitude_left': 'latitude', 'longitude_left': 'longitude'}, inplace=True)\n",
    "    \n",
    "    # Convert 'acq_date' to datetime\n",
    "    df['acq_date'] = pd.to_datetime(df['acq_date'])\n",
    "    \n",
    "    df = df.sort_values(by='acq_date')\n",
    "    \n",
    "    # Create 'date_cluster' column based on consecutive dates\n",
    "    df['date_cluster'] = (df['acq_date'].diff().dt.days > 1).cumsum()\n",
    "    \n",
    "    # Function to apply DBSCAN on each consecutive date cluster\n",
    "    def apply_dbscan(group):\n",
    "        coords = group[['latitude', 'longitude']].values \n",
    "        # Apply DBSCAN, hyperparameters are the same as Climada\n",
    "        db = DBSCAN(eps=15/111.12, min_samples=1).fit(coords)\n",
    "        group['regional_cluster'] = db.labels_\n",
    "        return group\n",
    "    \n",
    "    # Apply DBSCAN on each date cluster\n",
    "    df = df.groupby('date_cluster').apply(apply_dbscan)\n",
    "    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Create a unique 'event_id' for each unique combination of 'date_cluster' and 'regional_cluster'\n",
    "    df['event_id'] = df.groupby(['date_cluster', 'regional_cluster']).ngroup()\n",
    "    \n",
    "    df = df.sort_values(by='event_id').reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T03:43:04.214369Z",
     "start_time": "2024-07-23T03:43:04.207368Z"
    }
   },
   "id": "e671d22827bb58f1",
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.2 Load the function to shuffle and split data into training and testing according to event_id"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24844bc42599e48a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def shuffle_and_split(df, split_by_col, test_size=0.1, random_seed=42):\n",
    "    \"\"\"\n",
    "    This function shuffles the DataFrame with respect to 'event_id' and then splits the data\n",
    "    into training and test sets with approximately 10% test size with respect to 'event_id'.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame\n",
    "        split_by_col (str): The column name to split the data by\n",
    "        test_size (float): The proportion of the test set\n",
    "        random_seed (int): The seed for the random number generator\n",
    "        \n",
    "    Returns:\n",
    "        X_train (pd.DataFrame): Training features\n",
    "        X_test (pd.DataFrame): Test features\n",
    "        y_train (pd.Series): Training labels\n",
    "        y_test (pd.Series): Test labels\n",
    "    \"\"\"\n",
    "    # Shuffle the dataframe based on event_id\n",
    "    event_counts = df[split_by_col].value_counts().sort_index()\n",
    "    event_id_pairs = list(zip(event_counts.index, event_counts.values))\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(event_id_pairs)\n",
    "    \n",
    "    test_event_ids = []\n",
    "    current_test_rows = 0\n",
    "    total_rows = len(df)\n",
    "    test_rows_target = int(total_rows * test_size)\n",
    "    \n",
    "    for event_id, count in event_id_pairs:\n",
    "        current_test_rows += count\n",
    "        test_event_ids.append(event_id)\n",
    "        if current_test_rows >= test_rows_target:\n",
    "            break\n",
    "    \n",
    "    train_event_ids = [id for id, _ in event_id_pairs if id not in test_event_ids]\n",
    "    \n",
    "    X_train = df[df[split_by_col].isin(train_event_ids)].drop(columns=['ignited'])\n",
    "    y_train = df[df[split_by_col].isin(train_event_ids)]['ignited']\n",
    "    X_test = df[df[split_by_col].isin(test_event_ids)].drop(columns=['ignited'])\n",
    "    y_test = df[df[split_by_col].isin(test_event_ids)]['ignited']\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# X_train, X_test, y_train, y_test = shuffle_and_split(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T03:43:05.043643Z",
     "start_time": "2024-07-23T03:43:05.029375Z"
    }
   },
   "id": "54ca58bd7ec20886",
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c9c8a89097f6579"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def custom_cv_split(X, y, split_by_col, random_state, n_splits=5):\n",
    "    unique_event_ids = X[split_by_col].unique()\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(unique_event_ids)\n",
    "    fold_sizes = np.full(n_splits, len(unique_event_ids) // n_splits, dtype=int)\n",
    "    fold_sizes[:len(unique_event_ids) % n_splits] += 1\n",
    "    current = 0\n",
    "    for fold_size in fold_sizes:\n",
    "        test_event_ids = unique_event_ids[current:current + fold_size]\n",
    "        train_event_ids = np.setdiff1d(unique_event_ids, test_event_ids)\n",
    "        train_indices = X[X[split_by_col].isin(train_event_ids)].index\n",
    "        test_indices = X[X[split_by_col].isin(test_event_ids)].index\n",
    "        yield train_indices, test_indices\n",
    "        current += fold_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T03:43:06.334976Z",
     "start_time": "2024-07-23T03:43:06.319976Z"
    }
   },
   "id": "2d2bf4826e354f03",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# \n",
    "# def custom_cv_split(X, y, n_splits=5, random_state=42):\n",
    "#     unique_event_ids = X['event_id'].unique()\n",
    "#     np.random.seed(random_state)\n",
    "#     np.random.shuffle(unique_event_ids)\n",
    "#     fold_sizes = np.full(n_splits, len(unique_event_ids) // n_splits, dtype=int)\n",
    "#     fold_sizes[:len(unique_event_ids) % n_splits] += 1\n",
    "#     current = 0\n",
    "#     for fold_size in fold_sizes:\n",
    "#         test_event_ids = unique_event_ids[current:current + fold_size]\n",
    "#         train_event_ids = np.setdiff1d(unique_event_ids, test_event_ids)\n",
    "#         train_indices = X[X['event_id'].isin(train_event_ids)].index\n",
    "#         test_indices = X[X['event_id'].isin(test_event_ids)].index\n",
    "#         yield train_indices, test_indices\n",
    "#         current += fold_size\n",
    "# \n",
    "# def test_custom_cv_split():\n",
    "#     # Generate a sample dataframe\n",
    "#     data = {\n",
    "#         'event_id': [0, 0, 0, 1, 2, 2, 3, 3, 4, 5, 5, 5, 6, 6, 7, 7, 7, 7, 8, 8, 8, 8],\n",
    "#         'feature1': range(22),\n",
    "#         'feature2': range(22, 44),\n",
    "#         'ignited': [1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "#     }\n",
    "#     df = pd.DataFrame(data)\n",
    "#     X = df.drop(columns=['ignited'])\n",
    "#     y = df['ignited']\n",
    "#     \n",
    "#     # Test 1: Each split respects the event_id boundaries\n",
    "#     for train_indices, test_indices in custom_cv_split(X, y, n_splits=5):\n",
    "#         train_event_ids = X.loc[train_indices, 'event_id'].unique()\n",
    "#         test_event_ids = X.loc[test_indices, 'event_id'].unique()\n",
    "#         assert len(set(train_event_ids).intersection(set(test_event_ids))) == 0, \"Overlap of event_ids between train and test sets\"\n",
    "#     \n",
    "#     # Test 2: There is no overlap between training and validation sets for each split\n",
    "#     for train_indices, test_indices in custom_cv_split(X, y, n_splits=5):\n",
    "#         assert len(set(train_indices).intersection(set(test_indices))) == 0, \"Overlap of indices between train and test sets\"\n",
    "#     \n",
    "#     # Test 3: The number of splits is correct\n",
    "#     splits = list(custom_cv_split(X, y, n_splits=5))\n",
    "#     assert len(splits) == 5, \"Number of splits is incorrect\"\n",
    "#     \n",
    "#     # Test 4: The total number of rows in the splits matches the total number of rows in the input data\n",
    "#     test_indices_combined = np.concatenate([test_indices for _, test_indices in splits])\n",
    "#     assert len(test_indices_combined) == len(X), \"Total number of rows in the splits does not match the total number of rows in the input data\"\n",
    "#     \n",
    "#     # Test 5: Handle small number of splits\n",
    "#     small_splits = list(custom_cv_split(X, y, n_splits=2))\n",
    "#     assert len(small_splits) == 2, \"Small number of splits test failed: Number of splits is incorrect\"\n",
    "#     \n",
    "#     # Test 6: Correct splitting for small dataset\n",
    "#     small_data = {\n",
    "#         'event_id': [0, 0, 1, 1],\n",
    "#         'feature1': [10, 20, 30, 40],\n",
    "#         'feature2': [50, 60, 70, 80],\n",
    "#         'ignited': [1, 0, 1, 0]\n",
    "#     }\n",
    "#     small_df = pd.DataFrame(small_data)\n",
    "#     X_small = small_df.drop(columns=['ignited'])\n",
    "#     y_small = small_df['ignited']\n",
    "#     small_splits = list(custom_cv_split(X_small, y_small, n_splits=2))\n",
    "#     for train_indices, test_indices in small_splits:\n",
    "#         train_event_ids = X_small.loc[train_indices, 'event_id'].unique()\n",
    "#         test_event_ids = X_small.loc[test_indices, 'event_id'].unique()\n",
    "#         assert len(set(train_event_ids).intersection(set(test_event_ids))) == 0, \"Small dataset test failed: Overlap of event_ids between train and test sets\"\n",
    "#     \n",
    "#     print(\"All tests passed!\")\n",
    "# \n",
    "# # Run the tests\n",
    "# test_custom_cv_split()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T03:26:33.780376Z",
     "start_time": "2024-07-23T03:26:33.759376Z"
    }
   },
   "id": "972bc9bdab062320",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.3 Load the function to train and evaluate ML models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e155bdf92dde1424"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(df, random_state=42):\n",
    "    # Preprocess the dataframe\n",
    "    df = pd.get_dummies(df, columns=['land_cover'], prefix='land_cover')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df = df.drop(columns=['month', 'date', 'distance_km', 'confidence', 'geometry'])\n",
    "    df['fwi'].fillna(0, inplace=True)\n",
    "\n",
    "    # Split the data\n",
    "    X_train_val, X_test, y_train_val, y_test = shuffle_and_split(df, 'event_id', test_size=0.1, random_seed=random_state)\n",
    "    X_train_val = X_train_val.drop(columns=['latitude', 'longitude', 'brightness', 'bright_t31'])\n",
    "    X_test = X_test.drop(columns=['latitude', 'longitude', 'brightness', 'bright_t31'])\n",
    "\n",
    "    # Initialize dictionaries to store the best models, hyperparameters, and scores\n",
    "    classifier_names = [\"LogisticRegression\", \"XGBClassifier\"]\n",
    "    best_models = {name: None for name in classifier_names}\n",
    "    best_params = {name: None for name in classifier_names}\n",
    "    best_scores = {name: 0 for name in classifier_names}\n",
    "\n",
    "    # Define objective functions for Optuna\n",
    "    def logisticregression_objective(trial):\n",
    "        classifier_name = \"LogisticRegression\"\n",
    "        logistic_c = trial.suggest_float('logistic_c', 1e-5, 1e5, log=True)\n",
    "        classifier_obj = LogisticRegression(C=logistic_c, random_state=random_state)\n",
    "        model_pipeline = make_pipeline(StandardScaler(), classifier_obj)\n",
    "        scores = cross_val_score(model_pipeline, X_train_val, y_train_val, cv=list(custom_cv_split(X_train_val, y_train_val, split_by_col='event_id', random_state=random_state)), n_jobs=-1, scoring='roc_auc')\n",
    "        score = scores.mean()\n",
    "        if score > best_scores[classifier_name]:\n",
    "            best_scores[classifier_name] = score\n",
    "            best_params[classifier_name] = trial.params\n",
    "            best_models[classifier_name] = classifier_obj # classifier_obj remain untrained\n",
    "        return score\n",
    "\n",
    "    def xgboost_objective(trial):\n",
    "        classifier_name = \"XGBClassifier\"\n",
    "        xgb_params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 200, 2000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.2, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),\n",
    "            'random_state': random_state\n",
    "        }\n",
    "        classifier_obj = XGBClassifier(**xgb_params)\n",
    "        scores = cross_val_score(model_pipeline, X_train_val, y_train_val, cv=list(custom_cv_split(X_train_val, y_train_val, split_by_col='event_id', random_state=random_state)), n_jobs=-1, scoring='roc_auc')\n",
    "        score = scores.mean()\n",
    "        if score > best_scores[classifier_name]:\n",
    "            best_scores[classifier_name] = score\n",
    "            best_params[classifier_name] = trial.params\n",
    "            best_models[classifier_name] = classifier_obj # classifier_obj remain untrained\n",
    "        return score\n",
    "\n",
    "    # Optimize hyperparameters with Optuna\n",
    "    study = optuna.create_study(sampler=optuna.samplers.TPESampler(), direction='maximize')\n",
    "    study.optimize(logisticregression_objective, n_trials=20)\n",
    "    study.optimize(xgboost_objective, n_trials=100)\n",
    "\n",
    "    results = {}\n",
    "    for name in classifier_names:\n",
    "        if name == \"LogisticRegression\":\n",
    "            best_models[name].set_params(max_iter=200)\n",
    "            model_pipeline = make_pipeline(StandardScaler(), best_models[name])\n",
    "        else:\n",
    "            model_pipeline = best_models[name]\n",
    "\n",
    "        model_pipeline.fit(X_train_val, y_train_val)\n",
    "        train_accuracy = model_pipeline.score(X_train_val, y_train_val)\n",
    "        test_accuracy = model_pipeline.score(X_test, y_test)\n",
    "        y_pred = model_pipeline.predict(X_test)\n",
    "        classification_rep = classification_report(y_test, y_pred)\n",
    "        confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        results[name] = {\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"test_accuracy\": test_accuracy,\n",
    "            \"classification_report\": classification_rep,\n",
    "            \"confusion_matrix\": confusion_mat\n",
    "        }\n",
    "\n",
    "        if name == \"LogisticRegression\":\n",
    "            feature_importance = best_models[name].coef_[0]\n",
    "        else:\n",
    "            feature_importance = best_models[name].feature_importances_\n",
    "\n",
    "        feature_importance_df = pd.DataFrame({'feature': X_train_val.columns, 'importance': feature_importance})\n",
    "        feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "        results[name][\"feature_importance\"] = feature_importance_df\n",
    "\n",
    "    return results\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T03:43:12.765133Z",
     "start_time": "2024-07-23T03:43:12.744133Z"
    }
   },
   "id": "c7cf786755d721",
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Run ML model for each year"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd5579c337435486"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder = '../../climada_petals/data/wildfire/outputs/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T03:43:16.885868Z",
     "start_time": "2024-07-23T03:43:16.879363Z"
    }
   },
   "id": "78ebdf6130b89ba4",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "years = np.arange(2013, 2004)\n",
    "\n",
    "# Initialize an empty DataFrame to store the concatenated DataFrames\n",
    "gdf_all_years = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "    '''Step1: Load gdf'''\n",
    "    # construct the file path\n",
    "    file_path = os.path.join(folder, str(year), f'ignited_eu_{year}_gdf')\n",
    "    \n",
    "    # Load the DataFrame from the file\n",
    "    gdf = gpd.read_file(file_path)\n",
    "    \n",
    "    # Concatenate the loaded DataFrame with the initial DataFrame\n",
    "    gdf_all_years = pd.concat([gdf_all_years, gdf])\n",
    "    \n",
    "    gdf_all_years = gpd.GeoDataFrame(gdf_all_years, geometry=gdf_all_years.geometry, crs=gdf_all_years.crs)\n",
    "    \n",
    "    '''Step2: Group gdf into fire events'''\n",
    "    gdf_all_years = group_into_fire_events(gdf_all_years)\n",
    "    \n",
    "    '''Step3: Split data into training and testing sets and train and evaluate models'''\n",
    "    results = train_and_evaluate_models(gdf_all_years)\n",
    "    \n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T03:43:43.563014Z",
     "start_time": "2024-07-23T03:43:43.556014Z"
    }
   },
   "id": "2ef2daf7bffcecdc",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for LogisticRegression:\n",
      "Training Accuracy: 0.7700218833679412\n",
      "Test Accuracy: 0.7675706285786195\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.85      0.80      8629\n",
      "        True       0.79      0.67      0.73      7264\n",
      "\n",
      "    accuracy                           0.77     15893\n",
      "   macro avg       0.77      0.76      0.76     15893\n",
      "weighted avg       0.77      0.77      0.77     15893\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7297 1332]\n",
      " [2362 4902]]\n",
      "Feature Importance:\n",
      "            feature  importance\n",
      "0              fwi    0.199789\n",
      "4    land_cover_40    0.141254\n",
      "5    land_cover_50    0.112411\n",
      "9    land_cover_90    0.023947\n",
      "19  land_cover_126    0.019786\n",
      "2    land_cover_20    0.016416\n",
      "18  land_cover_125    0.008038\n",
      "12  land_cover_112    0.000000\n",
      "3    land_cover_30   -0.000506\n",
      "17  land_cover_124   -0.001221\n",
      "15  land_cover_116   -0.015308\n",
      "16  land_cover_121   -0.019716\n",
      "10  land_cover_100   -0.021827\n",
      "7    land_cover_70   -0.039546\n",
      "1        elevation   -0.041419\n",
      "13  land_cover_114   -0.041802\n",
      "14  land_cover_115   -0.044757\n",
      "6    land_cover_60   -0.046661\n",
      "21       month_sin   -0.047801\n",
      "8    land_cover_80   -0.049809\n",
      "11  land_cover_111   -0.100353\n",
      "22       month_cos   -0.106716\n",
      "20  land_cover_200   -0.151478\n",
      "------------------------------------\n",
      "Results for XGBClassifier:\n",
      "Training Accuracy: 0.826729869748516\n",
      "Test Accuracy: 0.8235701252123576\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.75      0.82      8629\n",
      "        True       0.76      0.91      0.82      7264\n",
      "\n",
      "    accuracy                           0.82     15893\n",
      "   macro avg       0.83      0.83      0.82     15893\n",
      "weighted avg       0.84      0.82      0.82     15893\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6496 2133]\n",
      " [ 671 6593]]\n",
      "Feature Importance:\n",
      "            feature  importance\n",
      "0              fwi    0.274153\n",
      "20  land_cover_200    0.152107\n",
      "4    land_cover_40    0.145927\n",
      "5    land_cover_50    0.101896\n",
      "11  land_cover_111    0.086640\n",
      "6    land_cover_60    0.054461\n",
      "22       month_cos    0.048469\n",
      "19  land_cover_126    0.047128\n",
      "21       month_sin    0.044218\n",
      "9    land_cover_90    0.023590\n",
      "1        elevation    0.021409\n",
      "16  land_cover_121    0.000000\n",
      "2    land_cover_20    0.000000\n",
      "18  land_cover_125    0.000000\n",
      "17  land_cover_124    0.000000\n",
      "3    land_cover_30    0.000000\n",
      "15  land_cover_116    0.000000\n",
      "13  land_cover_114    0.000000\n",
      "12  land_cover_112    0.000000\n",
      "10  land_cover_100    0.000000\n",
      "8    land_cover_80    0.000000\n",
      "7    land_cover_70    0.000000\n",
      "14  land_cover_115    0.000000\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for model, metrics in results.items():\n",
    "    print(f\"Results for {model}:\")\n",
    "    print(\"Training Accuracy:\", metrics['train_accuracy'])\n",
    "    print(\"Test Accuracy:\", metrics['test_accuracy'])\n",
    "    print(\"Classification Report:\\n\", metrics['classification_report'])\n",
    "    print(\"Confusion Matrix:\\n\", metrics['confusion_matrix'])\n",
    "    print(\"Feature Importance:\\n\", metrics['feature_importance'])\n",
    "    print('------------------------------------')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T03:43:47.635927Z",
     "start_time": "2024-07-23T03:43:47.627927Z"
    }
   },
   "id": "9c41cbde338d1cad",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6c1e54f70e2a52da"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
